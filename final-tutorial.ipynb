{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Data of Top 200 songs on Spotify\n",
    "## Amanuel Awoke\n",
    "##  Ferzam Mohammad\n",
    "## Josue Velasquez\n",
    "\n"
   ]
  },
  {
   "source": [
    "![d](https://i.guim.co.uk/img/media/ae483ce4f1bfc5497fee1b5387711d1ff0172ec9/232_0_3268_1963/master/3268.jpg?width=1200&quality=85&auto=format&fit=max&s=fcfceea59329a6bee9c9b75dd8d7a055)\n",
    "\n",
    "[Image from The Guardian](https://www.theguardian.com/music/2020/mar/19/musicians-ask-spotify-to-triple-payments-to-cover-lost-concert-revenue)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Motivation\n",
    "The music industry has changed a lot in the last decade with the introduction of streaming services like Apple Music or Spotify. Services like Spotify allow users to livestream music for personal consumption, often for free or for a subscription fee. These services have made it easier to consume music and have increased opportunities for people to start producing music, but they have also changed how musicians make money. Whenever a user listens to a song on a streaming service, the service typically keeps track of the number of “plays” that song has. Music artists are then paid a small amount based on the number of plays they have accumulated for their music. Given how little these artists are paid from streaming services, maximizing the amount of revenue made from a song seems pretty valuable for those looking to push out music to these services. Play count also indicates where a song stands in the streaming services’ popularity lists, and making it onto their top 100 or 200 songs is a factor considered in whether these songs are added to global, official top songs charts i.e. Billboard 200.\n",
    " \n",
    "Our group thought it would be interesting to see if we could try to make predictions for how popular a song might be given different features for a song (e.g. the genre of the song, how fast or slow it is, the key the song is written in, the time of year a song was released, how many listeners an artist already gets on average, etc.). If we can indicate how many plays a song will get, we can give a prediction for how much money a song will make on a streaming service. Much like the Moneyball scenario, it’s possible that artists are focusing on producing music that meets criteria which they think makes a song popular when, in reality, they should be focusing on other aspects of their music. Understanding what components of a song make it popular would help artists figure out the best way to produce music in order to make money off of these streaming services.\n",
    "\n",
    "The Moneyball story demonstrated the importance of data science in producing a strong baseball team, and while music is different from sports, our project should hopefully reflect similar data science practices in order to reach a valuable conclusion. It may be relatively straightforward to look at aspects like which genres make the most money or whether a song by Taylor Swift will end up on the top 200 chart given her “incredibly loyal fanbase” of over 40 million people, but maybe there are other similarities between popular songs that could indicate factors which help make a song more popular. Data science practices like t-tests (maybe) or machine learning models help us here by giving us tools to help identify characteristics in a song, clarify how those characteristics might relate to play count, and predict what the play count (or popularity) for a similar song could be given factors that we have determined have an affect on play count (or popularity)\n",
    "<One valuable conclusion might be the LACK OF money artists are being paid from streaming services, or how little they make off streaming services alone>\n",
    "\n",
    "From this point forward when we use the word \"track\" it is synonymous with \"song.\"\n",
    "\n",
    "## Goal Hypothesis\n",
    "Are there traits of a song that can be used to determine future success? If so, what are they?\n",
    "## Defining Success\n",
    "We are defining the success of a track by its appearance on the Top 200, as well as its ranking on the Top 200 (the higher the better).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "\n",
    "This is the first step in the data lifecycle where we must identify information to web scrape. We gather data from the [Spotify Charts Regional Top 200](https://spotifycharts.com/regional) to first identify which songs had the highest stream counts in the United States, dating back to January 1st 2017, to current day. Spotify Charts provides tracks with the highest stream count, their top 200 rank, and the artist(s) who created that song. Spotify Charts already compiles the data into Excel tables, so it isn't necessary to directly scrape from the website. If you wanted to download one yourself, at the top right of the website, select a date you'd like to download in the dropdown, then select further up \"Download to CSV.\" The pandas method read_csv() was used to process the Excel files into dataframes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spotipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were consistent download URLs of Excel sheets in relation to the date they recorded, we used a looped to retreive the links then later download all sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect links from spotify charts top 200 streams per day\n",
    "ref_str = \"https://spotifycharts.com/regional/global/daily/\"\n",
    "ref_arr = []\n",
    "# gets every day from janurary 2017 to October 2020\n",
    "\n",
    "for year in range(2017, 2018):\n",
    "    date = \"\"\n",
    "    \n",
    "    endingMonth = 12\n",
    "    if year == 2020:\n",
    "        endingMonth = 10\n",
    "        \n",
    "    for month in range (1, endingMonth + 1):\n",
    "       \n",
    "        dayCount = -1\n",
    "\n",
    "        #gets proper day count per month\n",
    "        thirtyDayCountMonths = [4, 6, 9, 11]\n",
    "        if month == 2:\n",
    "            dayCount = 29\n",
    "        elif month in thirtyDayCountMonths:\n",
    "            dayCount = 30\n",
    "        else:\n",
    "            dayCount = 31\n",
    "\n",
    "        if int(month) < 10:\n",
    "            month = \"0\" + str(month)\n",
    "        # for day in range (1, daycount + 1):\n",
    "        # for day in range (1, 16):\n",
    "           \n",
    "        #if int(day) < 10:\n",
    "        #    day = \"0\" + str(day)\n",
    "\n",
    "        date = str(year) + \"-\" + str(month) + \"-\" + \"01\" + \"/download\"\n",
    "        date = ref_str + date\n",
    "        ref_arr.append(date)\n",
    "\n",
    "ref_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop downloading and appending of dataframes \n",
    "\n",
    "df = pd.DataFrame(columns =['position', 'track_name', 'artist', 'streams', 'url', 'date'] )\n",
    "#make dir to save to\n",
    "path = \"sheets\"\n",
    "folderExists = False\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except FileExistsError:\n",
    "    print (\"Folder already exists\")\n",
    "    folderExists = True\n",
    "\n",
    "for i in ref_arr:\n",
    "\n",
    "    r = requests.get(i, allow_redirects = True)\n",
    "    #String manipulation to read from the correct csv files\n",
    "    date = i[48:58]\n",
    "    fileName = \"regional-global-daily-\" + date + \".csv\"\n",
    "    if not folderExists:\n",
    "        print(\"Downloading... \" + fileName)\n",
    "        open(fileName, \"wb\").write(r.content)\n",
    "\n",
    "        os.rename(fileName, \"sheets/\" + fileName)\n",
    "\n",
    "    df_new = pd.read_csv(path + \"/\" + fileName)\n",
    "    df_new.columns= ['position', 'track_name', 'artist', 'streams', 'url']\n",
    "    df_new['date'] = date\n",
    "    \n",
    "    df_new = df_new.iloc[1:] #deletes junk row from csv conversion\n",
    "    df = df.append(df_new)\n",
    "\n",
    "print(\"Done\")\n",
    "df = df.reset_index() # Sets index back to being the regular 0-based index. This is really helpful when trying to add more to the dataframe later, because otherwise there are lots of duplicate indices\n",
    "df['streams'] = df['streams'].astype(int) #streams are a string of a num, must wrap as type int always"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangled data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spotipy](https://spotipy.readthedocs.io/en/2.16.1/#) is a lightweight Python library for the [Spotify Web API](https://developer.spotify.com/documentation/web-api/) used to retrieve more detailed data for tracks now that their names have been retrieved from the Spotify Top 200. We must first authenticate our usage of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "\n",
    "SPOTIPY_CLIENT_ID=\"ea1a162fbc6f413990542b76ab82a168\"\n",
    "SPOTIPY_CLIENT_SECRET=\"a09882042ce54f158fdd2b6baaf2b26d\"\n",
    "SPOTIPY_CLIENT_REDIRECT=\"http://www.cs.umd.edu/class/fall2020/cmsc320-0201/\"\n",
    "\n",
    "scope = \"user-library-read\"\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope, client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET, redirect_uri=SPOTIPY_CLIENT_REDIRECT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by using the Spotify API to get more information about all the tracks we found in the top 200's chart for the timeframe we described above. The Spotify API gives us the ability to get \"audio features\" from a song given a song id that Spotify creates for every track. These \"audio features\" include characteristics like loudness, positivity, danceability, how energetic the song is, the speed of the song, and a couple other similar characteristics that have been determined by Spotify using their own machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we do need to get an id for every song and artist in our dataframe to be able to make queries through the Spotify API for a specific track or artist. Here, we get track and artist ids, and we also make a query for the audio features of each track id. We're doing these together for code efficiency, just because a large number of queries through the Spotify API can take time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "import openpyxl\n",
    "\n",
    "artist_id_list = []\n",
    "track_id_list = []\n",
    "popularity_index_list = []\n",
    "follower_count_list = []\n",
    "audio_features_df = pd.DataFrame()\n",
    "\n",
    "genre_list = []\n",
    "genre_filter = [\"rap\", \"pop\", \"edm\", \"rock\", \"other\"]\n",
    "\n",
    "\n",
    "\n",
    "#if cached df exists dont search again, else search again\n",
    "if not os.path.exists(\"cached_df.xlsx\"):\n",
    "    #Take each song and lookup its audio features, then create a dataframe for them\n",
    "    print(\"Searching...\")\n",
    "    for index, row in df.iterrows():\n",
    "        trackName = row['track_name']\n",
    "        track_id = \"\"\n",
    "        artist_id = \"\"\n",
    "        # We need to check if our track_name received was a nan value. Idk how these got in here, but there are nans\n",
    "        if(type(trackName) == str):\n",
    "            #delimit with +'s for spotipy search query\n",
    "            trackNameWithoutSpaces = '+'.join(trackName.split())\n",
    "            searchQuery = sp.search(trackNameWithoutSpaces, 1, 0)\n",
    "            if (len(searchQuery['tracks']['items']) != 0):\n",
    "                \n",
    "                track_object = searchQuery['tracks']['items'][0]\n",
    "                track_id = track_object['id']\n",
    "                track_id_list.append(track_id)\n",
    "\n",
    "                #if there are several artists, return the first artist\n",
    "                artist_object = track_object['artists'][0] if type(track_object['artists']) is list else track_object['artists']\n",
    "                artist_id = artist_object['id']\n",
    "                artist_id_list.append(artist_id)\n",
    "\n",
    "    \n",
    "                artist_object_real = sp.artist(artist_id)\n",
    "                # print(artist_object_real)\n",
    "                followers_object = artist_object_real['followers']\n",
    "                followers_value = followers_object['total']\n",
    "                follower_count_list.append(followers_value)\n",
    "                popularity_value = artist_object_real['popularity']\n",
    "                popularity_index_list.append(popularity_value)\n",
    "\n",
    "                # if artist_object_real['genres']\n",
    "                    # genre_value = \"Rap\"\n",
    "                # genre_list.append(genre_value)\n",
    "                # print(genre_list)\n",
    "\n",
    "\n",
    "\n",
    "                # print(popularity_index_list)\n",
    "\n",
    "\n",
    "            # If our query returned nothing then append a nan in the place of artist and track for this entry\n",
    "            else:\n",
    "                artist_id_list.append(np.nan)\n",
    "                track_id_list.append(np.nan)\n",
    "                \n",
    "                popularity_index_list.append(np.nan)\n",
    "                follower_count_list.append(np.nan)\n",
    "\n",
    "                genre_list.append(np.nan)\n",
    "        # If we had stored a nan, then just plan to append a nan in this position\n",
    "        else:\n",
    "            artist_id_list.append(np.nan)\n",
    "            track_id_list.append(np.nan)\n",
    "            \n",
    "            popularity_index_list.append(np.nan)\n",
    "            follower_count_list.append(np.nan)\n",
    "\n",
    "            genre_list.append(np.nan)\n",
    "\n",
    "       \n",
    "        #Defining audio features as nan to begin    \n",
    "        audiofeatures = {'duration_ms' : np.nan, 'key' : np.nan, 'mode' : np.nan, 'time_signature' : np.nan, 'acousticness' : np.nan, 'danceability' : np.nan, 'energy' : np.nan, 'instrumentalness' : np.nan, 'liveness' : np.nan, 'loudness' : np.nan, 'speechiness' : np.nan, 'valence' : np.nan, 'tempo' : np.nan, 'id' : np.nan, 'uri' : np.nan, 'track_href' : np.nan, 'analysis_url' : np.nan, 'type' : np.nan, }\n",
    "\n",
    "        # If we successfully found a track when we did our search, then get the audio features for that\n",
    "        if (track_id != \"\"):\n",
    "            audiofeatures = sp.audio_features(track_id)[0]\n",
    "        #Append the audio features\n",
    "        audio_features_df = audio_features_df.append(audiofeatures, ignore_index=True)\n",
    "\n",
    "    #adds artist id list \n",
    "    audio_features_df['artist_id'] = artist_id_list \n",
    "    audio_features_df['popularity_index'] = popularity_index_list\n",
    "    audio_features_df['follower_count'] = follower_count_list\n",
    "\n",
    "    # audio_features_df['genre'] = genre_list\n",
    "\n",
    "    # Store the created data frame into the cache\n",
    "    writer = pd.ExcelWriter('cached_df.xlsx', engine='openpyxl')\n",
    "    audio_features_df.to_excel(writer, sheet_name='Sheet1')\n",
    "    writer.save()\n",
    "    \n",
    "else: #access the cached df if it exist\n",
    " \n",
    "    print(\"Cached dataframe found.\")\n",
    "    audio_features_df = pd.read_excel(\"cached_df.xlsx\", engine = \"openpyxl\")\n",
    "    audio_features_df.drop([\"Unnamed: 0\"], axis=1, inplace=True) #delete position row since rank alraedy has this information\n",
    "\n",
    "audio_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Append audio features to master dataframe\n",
    "df['track_id'] = audio_features_df['id']\n",
    "df['duration_ms'] = audio_features_df['duration_ms']\n",
    "df['acousticness'] = audio_features_df['acousticness']\n",
    "df['danceability'] = audio_features_df['danceability']\n",
    "df['energy'] = audio_features_df['energy']\n",
    "df['instrumentalness'] = audio_features_df['instrumentalness']\n",
    "df['liveness'] = audio_features_df['liveness']\n",
    "df['loudness'] = audio_features_df['loudness']\n",
    "df['speechiness'] = audio_features_df['speechiness']\n",
    "df['valence'] = audio_features_df['valence']\n",
    "df['tempo'] = audio_features_df['tempo']\n",
    "df['artist_id'] = audio_features_df['artist_id']\n",
    "df['popularity_index'] = audio_features_df['popularity_index']\n",
    "df['follower_count'] = audio_features_df['follower_count']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "#plotting all the new metrics in our dataframe vs streams\n",
    "df['streams'] = df['streams'].astype(float)\n",
    "df['position'] = df['position'].astype(int)\n",
    "#this shows what got number 1? (below)\n",
    "# df.loc[df['position'] == 1].head(10) # Previously this was showing that every "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now gathered and manipulated valuable data for each track for each day recorded. The key elements are the following:\n",
    "- Track Name\n",
    "- Artist Name\n",
    "- Stream Count\n",
    "- Popularity value \n",
    "- Number of Followers\n",
    "- Position on Top 200\n",
    "- Date on the Top 200 (most songs stay for many days)\n",
    "\n",
    "The following details define the patterns and properties of music, the way they sound, and what mood they instill:\n",
    "- Duration\n",
    "  - The duration of the track in milliseconds.\n",
    "- Acousticness\n",
    "  - A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic. \n",
    "- Energy\n",
    "  - Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy. \n",
    "- Instrumentalness\n",
    "  - Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n",
    "- Liveness\n",
    "  - Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n",
    "- Loudness\n",
    "  - The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.\n",
    "- Speechiness \n",
    "  - Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. \n",
    "- Valence\n",
    "  - A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry). \n",
    "- Tempo\n",
    "  - The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration. \n",
    "\n",
    "The following are more extraneous details for identifying tracks in the data wrangling:\n",
    "- Track ID\n",
    "- Artist ID \n",
    "- URL\n",
    "\n"
   ]
  },
  {
   "source": [
    "Using this data, we begin trying to observe what traits of a song bring success.\n",
    "First we observe that there is a standard distrubtion of stream counts, meaning the mean stream count will most likely fall from 1-1.05 million."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram takes 100 random tracks, takes the average of all their streams, then does this 100 times\n",
    "#Is a standarrd deviation\n",
    "\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "data = []\n",
    "for i in range(0,100):\n",
    "    data.append(np.mean(df['streams'].sample(n=100)))\n",
    "plt.hist(data)\n",
    "plt.xlabel(\"Estimate\")\n",
    "plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "source": [
    "Our goal is to determine if there certain values of song properties that result in extremely high or low success.\n",
    "We create a dataframe that only saves the entry of a song at its peak stream count in the Top 200, meaning\n",
    "we are comparing all the peaks."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating version of table with no duplicates, keeping the last seen version of each song. It is a fair representation of success.\n",
    "\n",
    "no_dupes_df = df.copy()\n",
    "no_dupes_df = no_dupes_df.sort_values('streams', ascending=False).drop_duplicates(['artist', 'duration_ms', 'acousticness', 'danceability', 'energy'], keep='first') \n",
    "no_dupes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['popularity_index'], no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Popularity')\n",
    "plt.xlabel('popularity value')\n",
    "plt.ylabel('streams in millions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['follower_count'], no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Follower Count')\n",
    "plt.xlabel('number of artist followers')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "source": [
    "plt.scatter(no_dupes_df['duration_ms'], no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Song Duration')\n",
    "plt.xlabel('duration in milliseconds')\n",
    "plt.ylabel('streams in millions')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['acousticness'],no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Acousticness')\n",
    "plt.xlabel('acousticness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "source": [
    "plt.scatter(no_dupes_df['danceability'],no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Danceability')\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['energy'],no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Energy')\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['instrumentalness'],no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Instrumentalness')\n",
    "plt.xlabel('instrumentalness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['liveness'],no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Liveness')\n",
    "plt.xlabel('liveness scale of 0-1') \n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['loudness'],no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Loudness')\n",
    "plt.xlabel('loudness scale')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['speechiness'], no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Speechiness')\n",
    "plt.xlabel('speechiness scale of 0-.5')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['valence'],no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Valence')\n",
    "plt.xlabel('valence scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "source": [
    "Streams in relation to Tempo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['tempo'],no_dupes_df['streams'])\n",
    "plt.title('Streams in Relation to Tempo')\n",
    "plt.xlabel('tempo scale of 0-200')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "source": [
    "Observe this correlation matrix compiling on scatter plots above"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = no_dupes_df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "source": [
    "It seems like each individual feature has very little effect on the number of streams, which would support our findings above. After seeing this, we had a couple of ideas. It is possible different features we are currently tracking work together to make a song popular, but it is also possible we are missing other important features. After looking back at the most popular songs over the course of our entire dataframe, we noticed the majority of artists were well known or already accomplished. While it is obvious that an artists \"followers\" or typical listeners will increase the number of streams a song will get, it would be interesting to know if the number of typical listeners was more important than all these other aspects of the song."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Top 10\n",
    "Here we observe the traits of specifically the song at the ranks 1-5. The song in these positoins is likely to change, so there will be different values for the same position at times."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10s = df.loc[df['position'] <= 10]\n",
    "#lists for legend to remove redundant code\n",
    "color_list = ['r', 'orange', 'yellow', 'lime',  'cyan', 'b', 'brown' , 'violet', 'purple', 'black']\n",
    "top10_legend = ['Rank 1', 'Rank 2', 'Rank 3', 'Rank 4', 'Rank 5', 'Rank 6','Rank 7','Rank 8','Rank 9','Rank 10']\n",
    "\n",
    "#method to remove redundant code in plotting\n",
    "def plotTop10(name):\n",
    "    i = 0\n",
    "    for index, row in top10s.iterrows():\n",
    "        plt.scatter(row[name],row['streams'], color=color_list[i])\n",
    "        i = (i + 1) % 10\n",
    "\n",
    "\n",
    "top10s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotTop10('popularity_index')\n",
    "plt.title('Top 10 Streams in Relation to Popularity')\n",
    "plt.xlabel('Artist Popularity Value')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTop10('follower_count')\n",
    "plt.title('Top 10 Streams in Relation to Follower Count')\n",
    "plt.xlabel('Follower Count in 10 millions')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotTop10('duration_ms')\n",
    "plt.title('Top 10 Streams in Relation to Duration')\n",
    "plt.xlabel('duration in milliseconds')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph Shows how the duration of a song in milliseconds compares to the number of streams that song received, and we're only using the first 10 pieces of data from our dataframe. This shows us that the songs with the most streams from this set of data are songs which are > 240000 ms, or 4 minutes. This is surprising, because the average song is usually around 3 minutes and 30 seconds or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotTop10('acousticness')\n",
    "plt.title('Top 10 Streams in Relation to Acousticness')\n",
    "plt.xlabel('acousticness scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph displays a confidence score for how likely it is that a song is acoustic (with a value of 1 being very likely that the song is acoustic) compared to the number of streams the song has. All of the confidence scores are less than .5, which indicates most of these songs are probably not acoustic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotTop10('energy')\n",
    "plt.title('Top 10 Streams in Relation to Energy')\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows how the \"energy\" of a song, or generally how noisy and fast the song is, compares to the number of streams for the top 10 songs on the 1st of January. Here, we see that the songs with the most streams are around or above .6 on the energy scale (a higher score means the song is higher energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTop10('danceability')\n",
    "plt.title('Top 10 Streams in Relation to Danceability')\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows how \"danceable\" a song is using a value provided to us by the Spotify API comapred to the number of streams that song got. Danceability is measured as a value from 0 to 1, where 1 is most danceable. This graph appears to be similar to the graph describing, so they may have been determined using similar characteristisc (i.e. both are measuring how upbeat or fast a song is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotTop10('loudness')\n",
    "plt.title('Top 10 Streams in Relation to Loudness')\n",
    "plt.xlabel('loudness in decibels')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph describes the average volume of each track in our top 10s data set compared to the number of streams each song had. It appears to trend similarly to the last two graphs, indicating that the volume of a track may be correlated with how danceable or energetic a song is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotTop10('valence')\n",
    "plt.xlabel('valence scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph describes the \"valence\" of a song compared to the # of streams it got. Valence is described as the \"positivity\" of a song where \"Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry),\" according to the Spotify API reference. The reference does not describe how this value is determined, but our data seems to show there may be a correlation between valence and the number of streams a song is getting in the set of number 1 songs. However, this graph does not take into account the other features for the songs. It may be worth trying to consider songs where features except for this one are held to a constant, so that we can consider if there is a correlation between this value and the number of streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotTop10('tempo')\n",
    "plt.title('Top 10 Streams in Relation to Beats Per Minute (BPM)')\n",
    "plt.xlabel('tempo scale of 0-200 Beats Per Minute (BPM)')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(top10_legend)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph describes the tempo of a song comapred to the number of streams that song has. Given our dataset, it is unclear whether there is a correlation between the tempo of a song and the number of streams it gets."
   ]
  },
  {
   "source": [
    "### Correlation of the top 10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = top10s.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "source": [
    "### Unique Relationships"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appeared to be a potential relationship between valence and the number of streams a song was getting both in our correlation chart and how rank 1 songs performed in our graph of the top 10 tracks each month, so it might be interesting to look at what the different features are like for songs with a high valence (.4 or higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTracks = df.loc[df['valence'] > .4]\n",
    "highValenceTracks.sort_values('streams', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have duplicate pieces of data, so lets remove the duplicates for this test. We're going to try to keep the versions of the song that have the most streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTracks = highValenceTracks.sort_values('streams', ascending=False).drop_duplicates(['artist', 'duration_ms', 'acousticness', 'danceability', 'energy'], keep='first') # Keeping the last seen version of each song, as that will probably hold it's total streams more accurately\n",
    "highValenceTracks.sort_values('streams', ascending=False).head(10)"
   ]
  },
  {
   "source": [
    "Here are the first few tracks from our list of songs with high valences."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTracks = highValenceTracks.sort_values('valence', ascending=False)\n",
    "highValenceTracks.head()"
   ]
  },
  {
   "source": [
    "Here's a plot displaying the number of streams fore each song with a high valence compared to their valence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(highValenceTracks['valence'], highValenceTracks['streams'])\n",
    "plt.title(\"Streams Compared to Valence For Song With Valence > .4\")\n",
    "plt.xlabel(\"Valence Value From 0 to 1\")\n",
    "plt.ylabel(\"Streams in Millions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No longer seeing the relationship we were seeing earlier between valence and number of streams. Maybe the relationship that leads to more streams is a combination of these features together. It might be worth trying to see if there is a relationship between streams and a combination of features like valence AND loudness or valence AND danceability"
   ]
  },
  {
   "source": [
    "Let's try categorizing our data into groups with different levels of valences. This allows us to bound valenece, which helps us treat it more like a constant. Then, we could see how other features compare to streams when valence is held within certain levels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTracks = df.loc[(df['valence'] >= .5) & (df['valence'] < .8)]\n",
    "veryHighValenceTracks = df.loc[df['valence'] >= .8]\n",
    "lowValenceTracks = df.loc[(df['valence'] < .5) & (df['valence'] >= .3)]\n",
    "veryLowValenceTracks = df.loc[df['valence'] <= .3]\n",
    "#lowValenceTracks.head()\n",
    "#highValenceTracks.head()"
   ]
  },
  {
   "source": [
    "First, we can try to looking at how danceability performs with different bounded groups of valence. We will color code the valence groups, so that we can easily see which tracks have a high, medium-high, medium-low, or low valence."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting songs with a high valence and varying levels of danceability against streams to see if these two values work together to impact stream counts\n",
    "plt.scatter(veryLowValenceTracks['danceability'],veryLowValenceTracks['streams'], color=\"blue\")\n",
    "plt.scatter(lowValenceTracks['danceability'],lowValenceTracks['streams'], color=\"turquoise\")\n",
    "plt.scatter(highValenceTracks['danceability'],highValenceTracks['streams'], color=\"yellow\")\n",
    "plt.scatter(veryHighValenceTracks['danceability'],veryHighValenceTracks['streams'], color=\"red\")\n",
    "plt.title('Danceability and streams for songs with bounded valences')\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(['Song with valence < .3', 'Song with valence < .5 and > .3', 'Song with valence > .5 and < .8', 'Song with valence > .8'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph displays how the danceability of a song compares to the number of streams it has for songs that have a high valence (>.5). While there is little indication of a linear correlation, it appears that the songs with the most streams all also have a danceability of > .5. "
   ]
  },
  {
   "source": [
    "Using this set of data where valence is color coded by groups of values, let's try to plot other features against streams and see if valence + another feature has any effect on the number of streams. We can try considering follower count next, as that value appeared to have a slight positive correlation with streams in our correlation chart."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting songs with varying levels of followers within certain valence levels against streams to see if these two values work together to impact stream counts\n",
    "plt.scatter(veryLowValenceTracks['follower_count'],veryLowValenceTracks['streams'], color=\"blue\")\n",
    "plt.scatter(lowValenceTracks['follower_count'],lowValenceTracks['streams'], color=\"turquoise\")\n",
    "plt.scatter(highValenceTracks['follower_count'],highValenceTracks['streams'], color=\"yellow\")\n",
    "plt.scatter(veryHighValenceTracks['follower_count'],veryHighValenceTracks['streams'], color=\"red\")\n",
    "plt.title('Follower Count and Streams for Songs With Different Valence Bounds')\n",
    "plt.xlabel('Follower count in tens of millions of followers')\n",
    "plt.ylabel('Streams in millions')\n",
    "plt.legend(['Song with valence < .3', 'Song with valence < .5 and > .3', 'Song with valence > .5 and < .8', 'Song with valence > .8'])"
   ]
  },
  {
   "source": [
    "This graph shows that the majority of songs in our entire set of data are within that bottom left corner of the graph, and this cluster includes varrying levels of valence. This means that different amounts of followers with bounded amounts of valence have little to do with the number of streams."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Another variable that appeared to have a slight correlation with streams was the loudness of a song. We can try to make a plot similar to our previous two plots where we instead measure loudness on the x-axis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting songs with varying levels of loudness within certain valence levels against streams to see if these two values work together to impact stream counts\n",
    "plt.scatter(veryLowValenceTracks['loudness'],veryLowValenceTracks['streams'], color=\"blue\")\n",
    "plt.scatter(lowValenceTracks['loudness'],lowValenceTracks['streams'], color=\"turquoise\")\n",
    "plt.scatter(highValenceTracks['loudness'],highValenceTracks['streams'], color=\"yellow\")\n",
    "plt.scatter(veryHighValenceTracks['loudness'],veryHighValenceTracks['streams'], color=\"red\")\n",
    "plt.title('Loudness and Streams for Songs With Different Valence Bounds')\n",
    "plt.xlabel('Loudness in Decibels')\n",
    "plt.ylabel('Streams in Millions')\n",
    "plt.legend(['Song with valence < .3', 'Song with valence < .5 and > .3', 'Song with valence > .5 and < .8', 'Song with valence > .8'])"
   ]
  },
  {
   "source": [
    "While streams appears to have little correlation with our variables loudness and valence, it does appear that valence and loudness have a correlation. We start to see higher valences as songs gets louder, but this seems relatively intuitive as \"negative\" songs are probably quieter and more somber. It may also be noteworthy that songs that did very well all had a loudness of > -15 decibels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "These last 3 graphs seem to indicate that bounded levels of valence in conjunction with varying levels of the other features we measured have little to do with stream count. We did find that songs which performed exceptionally well had a loudness of above -15 decibels or had a danceability of greater than .6, but it was hard to see other relationships between our variables and streams otherwise."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In our correlation chart, one interesting relationship we noticed was the positive correlation between follower count and acousticness of a song. Follower count likely has an effect on a song's streams, just because the people following an artist are probably interested in the artist. Even if a user is uninterested in an artist they follow, they will at least get notifications of that artist's latest releases or recommendations of similar work. We can try to explore this relationship below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by getting the number of followers each artist has for every track entry in our dataframe. The Spotify API also provides a \"popularity\" index from 0 to 100, with 100 being the most popular. We will get this information, as well. There will be repetition between duplicate entries for an artist, but we are keeping these in so that we can still build a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Popularity and follower count computed at the beginning\n",
    "df['popularity_index']\n",
    "df['follower_count']\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "Recall that we have saved a dataframe with no duplicates."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dupes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the popularities plotted against the number of streams a song has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(no_dupes_df['popularity_index'], no_dupes_df['streams'])\n",
    "plt.xlabel(\"Popularity of artist from 0 to 100\")\n",
    "plt.ylabel(\"Streams in millions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are artists in the top 5 positions that have relatively low popularity indices compared to other artists on the top 200 chart. Understanding how these artists got to these high positions given low popularity indices would be valuabe. Let's try to locate all of these top 200 tracks that came from artists with low popularity indices, and see if we can learn from that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowPopularityArtists = df.loc[df['popularity value'] < ] # Learning about songs on the top 200 chart with low artist popularity might help us understand what is actually important in trying to get a song on the top 200 chart"
   ]
  },
  {
   "source": [
    "# Insight\n",
    "\n",
    "In the final step of the data cycle, we draw conclusions based off our analysis to inform decisions made based on the data.\n",
    "\n",
    "Does popularity/followers make a difference?\n",
    "\n",
    "From our data visualization conclusions, especially our correlation matrix, it is shown that success (stream count) of a song has a positive and sometimes strong positive correlation with popularity, number of followers, loudness, valence, energy, and accousticness. When obeserving the Top 200, note that the while these correlations are merely postive, when observing the top 10, they are much more strongly positvely correlated. Liveness, tempo, and instrumentalness of have negative to strong negative correlation with success. \n",
    "\n",
    "\n",
    "The loudness of songs brings up an interesting reminder of the [Loudness War](https://en.wikipedia.org/wiki/Loudness_war) in the early 1940s. During the loudness war, even though increasing the loudness of a song ultimately reduced its fidelity (fine details), critics preferred the increasing levels. This may be an echo of the impacts of this cultural trend, or perhaps people simply like their music loud, even if at a lower quality.\n",
    "\n",
    "We can conclude that a song by an artist with at least 200,000 followers, a popularity value of 80, a loudness value of -8, danceability x, valence x, energy x, accousticness x, is likely to enter the top 200 and potentially the top 10.\n",
    "\n",
    "Observe the next years data (here we show our estimate was right)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}