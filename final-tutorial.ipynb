{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Data of Top 200 songs on Spotify\n",
    "## Amanuel Awoke\n",
    "##  Ferzam M\n",
    "## Josue Velasquez"
   ]
  },
  {
   "source": [
    "# Introduction\n",
    "## Motivation\n",
    "The music industry has changed a lot in the last decade with the introduction of streaming services like Apple Music or Spotify. Services like Spotify allow users to livestream music for personal consumption, often for free or for a subscription fee. These services have made it easier to consume music and have increased opportunities for people to start producing music, but they have also changed how musicians make money. Whenever a user listens to a song on a streaming service, the service typically keeps track of the number of “plays” that song has. Music artists are then paid a small amount based on the number of plays they have accumulated for their music. Given how little these artists are paid from streaming services, maximizing the amount of revenue made from a song seems pretty valuable for those looking to push out music to these services. Play count also indicates where a song stands in the streaming services’ popularity lists, and making it onto their top 100 or 200 songs is a factor considered in whether these songs are added to global, official top songs charts i.e. Billboard 200.\n",
    " \n",
    "Our group thought it would be interesting to see if we could try to make predictions for how popular a song might be given different features for a song (e.g. the genre of the song, how fast or slow it is, the key the song is written in, the time of year a song was released, how many listeners an artist already gets on average, etc.). If we can indicate how many plays a song will get, we can give a prediction for how much money a song will make on a streaming service. Much like the Moneyball scenario, it’s possible that artists are focusing on producing music that meets criteria which they think makes a song popular when, in reality, they should be focusing on other aspects of their music. Understanding what components of a song make it popular would help artists figure out the best way to produce music in order to make money off of these streaming services.\n",
    "\n",
    "The Moneyball story demonstrated the importance of data science in producing a strong baseball team, and while music is different from sports, our project should hopefully reflect similar data science practices in order to reach a valuable conclusion. It may be relatively straightforward to look at aspects like which genres make the most money or whether a song by Taylor Swift will end up on the top 200 chart given her “incredibly loyal fanbase” of over 40 million people, but maybe there are other similarities between popular songs that could indicate factors which help make a song more popular. Data science practices like t-tests (maybe) or machine learning models help us here by giving us tools to help identify characteristics in a song, clarify how those characteristics might relate to play count, and predict what the play count (or popularity) for a similar song could be given factors that we have determined have an affect on play count (or popularity)\n",
    "<One valuable conclusion might be the LACK OF money artists are being paid from streaming services, or how little they make off streaming services alone>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Collect Data\n",
    "\n",
    "This is the first step in the data lifecycle where we must identify information to web scrape. We gather data from the [Spotify Charts Regional Top 200](https://spotifycharts.com/regional) to first identify which songs had the highest stream counts in the United States, dating back to January 1st 2017, to current day. Spotify Charts provides tracks with the highest stream count, their top 200 rank, and the artist(s) who created that song. Spotify Charts already compiles the data into Excel tables, so it isn't necessary to directly scrape from the website. If you wanted to download one yourself, at the top right of the website, select a date you'd like to download in the dropdown, then select further up \"Download to CSV.\" The pandas method read_csv() was used to process the Excel files into dataframes.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spotipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were consistent download URLs of Excel sheets in relation to the date they recorded, we used a looped to retreive the links then later download all sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect links from spotify charts top 200 streams per day\n",
    "ref_str = \"https://spotifycharts.com/regional/global/daily/\"\n",
    "ref_arr = []\n",
    "# gets every day from janurary 2017 to October 2020\n",
    "\n",
    "# for year in range(2017, 2021):\n",
    "for year in range(2017, 2018):\n",
    "    date = \"\"\n",
    "    \n",
    "    endingMonth = 12\n",
    "    if year == 2020:\n",
    "        endingMonth = 10\n",
    "        \n",
    "    # for month in range (1, endingMonth + 1):\n",
    "    for month in range (1,2):\n",
    "       \n",
    "        dayCount = -1\n",
    "\n",
    "        #gets proper day count per month\n",
    "        thirtyDayCountMonths = [4, 6, 9, 11]\n",
    "        if month == 2:\n",
    "            dayCount = 29\n",
    "        elif month in thirtyDayCountMonths:\n",
    "            dayCount = 30\n",
    "        else:\n",
    "            dayCount = 31\n",
    "\n",
    "        if int(month) < 10:\n",
    "            month = \"0\" + str(month)\n",
    "        # for day in range (1, daycount + 1):\n",
    "        for day in range (1, 16):\n",
    "           \n",
    "            if int(day) < 10:\n",
    "                day = \"0\" + str(day)\n",
    "\n",
    "            date = str(year) + \"-\" + str(month) + \"-\" + str(day) + \"/download\"\n",
    "            date = ref_str + date\n",
    "            ref_arr.append(date)\n",
    "\n",
    "ref_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop downloading and appending of dataframes \n",
    "\n",
    "df = pd.DataFrame(columns =['position', 'track_name', 'artist', 'streams', 'url', 'date'] )\n",
    "#make dir to save to\n",
    "path = \"sheets\"\n",
    "folderExists = False\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    print (\"Folder already exists\")\n",
    "    folderExists = True\n",
    "\n",
    "    for i in ref_arr:\n",
    "\n",
    "        r = requests.get(i, allow_redirects = True)\n",
    "        #String manipulation to read from the correct csv files\n",
    "        date = i[48:58]\n",
    "        fileName = \"regional-global-daily-\" + date + \".csv\"\n",
    "        if not folderExists:\n",
    "            print(\"Downloading... \" + filename)\n",
    "            open(fileName, \"wb\").write(r.content)\n",
    "\n",
    "            os.rename(fileName, \"sheets/\" + fileName)\n",
    "\n",
    "\n",
    "        df_new = pd.read_csv(path + \"/\" + fileName)\n",
    "        df_new.columns= ['position', 'track_name', 'artist', 'streams', 'url']\n",
    "        df_new['date'] = date\n",
    "        \n",
    "        df_new = df_new.iloc[1:] #deletes junk row from csv conversion\n",
    "        df = df.append(df_new)\n",
    "\n",
    "    print(\"Done\")\n",
    "df.drop(['position'], axis=1, inplace=True) #delete position row since rank alraedy has this information\n",
    "#streams are a string of a num, must wrap as type int always\n",
    "df['streams'] = df['streams'].astype(int)"
   ]
  },
  {
   "source": [
    "## Wrangled data into dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "# Data Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "[Spotipy](https://spotipy.readthedocs.io/en/2.16.1/#) is a lightweight Python library for the [Spotify Web API](https://developer.spotify.com/documentation/web-api/) used to retrieve more detailed data for tracks now that their names have been retrieved from the Spotify Top 200. We must first authenticate our usage of the API."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "\n",
    "SPOTIPY_CLIENT_ID=\"ea1a162fbc6f413990542b76ab82a168\"\n",
    "SPOTIPY_CLIENT_SECRET=\"a09882042ce54f158fdd2b6baaf2b26d\"\n",
    "SPOTIPY_CLIENT_REDIRECT=\"http://www.cs.umd.edu/class/fall2020/cmsc320-0201/\"\n",
    "\n",
    "scope = \"user-library-read\"\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope, client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET, redirect_uri=SPOTIPY_CLIENT_REDIRECT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "audioFeaturesDf = pd.DataFrame(columns=[\"duration_ms\", \"key\", \"mode\", \"time_signature\", \"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"valence\", \"tempo\", \"id\", \"uri\", \"track_href\", \"analysis_url\", \"type\"])\n",
    "\n",
    "#Example lookup of a song \n",
    "trackName = df.iloc[0].at['track_name']\n",
    "trackNameWithoutSpaces = '+'.join(trackName.split())\n",
    "trackItem = sp.search(trackNameWithoutSpaces, 1, 0)\n",
    "track_id = trackItem['tracks']['items'][0]['id']\n",
    "audiofeatures = sp.audio_features(track_id)\n",
    "print(track_id)\n",
    "print(audiofeatures[0]['danceability'])\n",
    "# print(row['track_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "\n",
    "#open time counter\n",
    "tic = time.perf_counter()\n",
    "\n",
    "#if cached df exists dont search again, else search again\n",
    "if not os.path.exists(\"cached_df.xlsx\"):\n",
    "    #Take each song and lookup its audio features, then create a dataframe for them\n",
    "    print(\"Searching...\")\n",
    "    for index, row in df.iterrows():\n",
    "        trackName = row['track_name']\n",
    "        trackNameWithoutSpaces = '+'.join(trackName.split())\n",
    "        trackItem = sp.search(trackNameWithoutSpaces, 1, 0)\n",
    "        audiofeatures = {'duration_ms' : np.nan, 'key' : np.nan, 'mode' : np.nan, 'time_signature' : np.nan, 'acousticness' : np.nan, 'danceability' : np.nan, 'energy' : np.nan, 'instrumentalness' : np.nan, 'liveness' : np.nan, 'loudness' : np.nan, 'speechiness' : np.nan, 'valence' : np.nan, 'tempo' : np.nan, 'id' : np.nan, 'uri' : np.nan, 'track_href' : np.nan, 'analysis_url' : np.nan, 'type' : np.nan, }\n",
    "        if (len(trackItem['tracks']['items']) != 0):\n",
    "            track_id = trackItem['tracks']['items'][0]['id']\n",
    "            audiofeatures = sp.audio_features(track_id)[0]\n",
    "        audioFeaturesDf = audioFeaturesDf.append(audiofeatures, ignore_index=True)\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter('cached_df.xlsx', engine='openpyxl')\n",
    "\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    audioFeaturesDf.to_excel(writer, sheet_name='Sheet1')\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Searches took {toc - tic:0.4f} mf seconds damn\")\n",
    "\n",
    "else: #access the cached\n",
    " \n",
    "    print(\"Cached dataframe found.\")\n",
    "    audioFeaturesDf = pd.read_excel(\"cached_df.xlsx\", engine = \"openpyxl\")\n",
    "    audioFeaturesDf.drop([\"Unnamed: 0\"], axis=1, inplace=True) #delete position row since rank alraedy has this information\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audioFeaturesDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Append audio features to master dataframe\n",
    "audioFeaturesDf\n",
    "df['duration_ms'] = audioFeaturesDf['duration_ms']\n",
    "df['acousticness'] = audioFeaturesDf['acousticness']\n",
    "df['danceability'] = audioFeaturesDf['danceability']\n",
    "df['energy'] = audioFeaturesDf['energy']\n",
    "df['instrumentalness'] = audioFeaturesDf['instrumentalness']\n",
    "df['liveness'] = audioFeaturesDf['liveness']\n",
    "df['loudness'] = audioFeaturesDf['loudness']\n",
    "df['speechiness'] = audioFeaturesDf['speechiness']\n",
    "df['valence'] = audioFeaturesDf['valence']\n",
    "df['tempo'] = audioFeaturesDf['tempo']\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "#plotting all the new metrics in our dataframe vs streams\n",
    "df['streams'] = df['streams'].astype(float)\n",
    "df['position'] = df['position'].astype(int)\n",
    "df.loc[df['position'] == 1].head(10) # Previously this was showing that every "
   ]
  },
  {
   "source": [
    "# Data Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram takes 100 random tracks, takes the average of all their streams, then does this 100 times\n",
    "#Is a standarrd deviation\n",
    "\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "#data = df['tempo'].sample(n=10).array\n",
    "data = []\n",
    "for i in range(0,100):\n",
    "    data.append(np.mean(df['streams'].sample(n=100)))\n",
    "print(data)\n",
    "plt.hist(data)\n",
    "plt.xlabel(\"Estimate\")\n",
    "plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#Get averages of each col\n",
    "duration_mean = np.mean(df['duration_ms'])\n",
    "acousticness_mean = np.mean(df['acousticness'])\n",
    "danceability_mean = np.mean(df['danceability'])\n",
    "energy_mean = np.mean(df['energy'])\n",
    "instrumentalness_mean = np.mean(df['instrumentalness'])\n",
    "liveness_mean = np.mean(df['liveness'])\n",
    "loudness_mean = np.mean(df['loudness'])\n",
    "speechiness_mean = np.mean(df['speechiness'])\n",
    "valence_mean = np.mean(df['valence'])\n",
    "tempo_mean = np.mean(df['tempo'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(duration_mean)\n",
    "# line = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "\n",
    "# for crime in crimes:\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for region in regions:\n",
    "#         x.append(region[\"Total\"].values)\n",
    "#         y.append(region[crime].values)\n",
    "        \n",
    "        \n",
    "#     x = np.array(x)\n",
    "#     x = x.flatten()\n",
    "#     y = np.array(y)\n",
    "#     y = y.flatten()\n",
    "    \n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     plt.title(crime)\n",
    "        \n",
    "# line = linear_model.LinearRegression()\n",
    "# x = np.array(df['duration_ms']).flatten()\n",
    "# y = np.array(df['streams']).flatten()\n",
    "# print(x)\n",
    "# line.fit(x,y)\n",
    "# predicted = line.predict(x.reshape(-1,1))\n",
    "    \n",
    "# #     r_value = line.score(x.reshape(-1,1),y)\n",
    "        \n",
    "        \n",
    "# #     plt.plot(x,predicted, c='r', label=r_value)\n",
    "# #     plt.legend()\n",
    "    \n",
    "# #     plt.show()\n",
    "# #     plt.close()\n",
    "\n",
    "# plt.scatter(x, y)\n",
    "# print(type(df['streams']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do i get rows with values in a range\n",
    "#where dancability\n",
    "\n",
    "# df_dance = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['duration_ms'], df['streams'])\n",
    "plt.xlabel('duration in milliseconds')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['acousticness'],df['streams'])\n",
    "plt.xlabel('accousticness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['danceability'],df['streams'])\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['energy'],df['streams'])\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['instrumentalness'],df['streams'])\n",
    "plt.xlabel('instrumentalness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['liveness'],df['streams'])\n",
    "plt.xlabel('liveness scale of 0-1') \n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['loudness'],df['streams'])\n",
    "plt.xlabel('loudness SCALE???????????????????')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['speechiness'],df['streams'])\n",
    "plt.xlabel('speechiness scale of 0-.5')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['valence'],df['streams'])\n",
    "plt.xlabel('valence scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['tempo'],df['streams'])\n",
    "plt.xlabel('tempo scale of 0-200')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#violin plot of genre vs streams in millions\n",
    "# ax = sns.violinplot(x='genre', y='streams', data=df, palette='muted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['date'],df['streams'])\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "source": [
    "# Insight\n",
    "Does popularity/followers make a difference?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_list = ['r', 'cyan', 'purple', 'b', 'green']\n",
    "\n",
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['duration_ms'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('duration in milliseconds')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])\n"
   ]
  },
  {
   "source": [
    "This graph Shows how the duration of a song in milliseconds compares to the number of streams that song received, and we're only using the first 10 pieces of data from our dataframe. This shows us that the songs with the most streams from this set of data are songs which are > 240000 ms, or 4 minutes. This is surprising, because the average song is usually around 3 minutes and 30 seconds or less."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['acousticness'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('accousticness scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph displays a confidence score for how likely it is that a song is acoustic (with a value of 1 being very likely that the song is acoustic) compared to the number of streams the song has. All of the confidence scores are less than .5, which indicates most of these songs are probably not acoustic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['energy'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph shows how the \"energy\" of a song, or generally how noisy and fast the song is, compares to the number of streams for the top 10 songs on the 1st of January. Here, we see that the songs with the most streams are around or above .6 on the energy scale (a higher score means the song is higher energy)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['danceability'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph shows how \"danceable\" a song is using a value provided to us by the Spotify API comapred to the number of streams that song got. Danceability is measured as a value from 0 to 1, where 1 is most danceable. This graph appears to be similar to the graph describing, so they may have been determined using similar characteristisc (i.e. both are measuring how upbeat or fast a song is)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['loudness'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('loudness in decibels')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph describes the average volume of each track in our top 5s data set compared to the number of streams each song had. It appears to trend similarly to the last two graphs, indicating that the volume of a track may be correlated with how danceable or energetic a song is."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['valence'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('valence scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph describes the \"valence\" of a song compared to the # of streams it got. Valence is described as the \"positivity\" of a song where \"Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry),\" according to the Spotify API reference. The reference does not describe how this value is determined, but our data seems to show there may be a correlation between valence and the number of streams a song is getting in the set of number 1 songs. However, this graph does not take into account the other features for the songs. It may be worth trying to consider songs where features except for this one are held to a constant, so that we can consider if there is a correlation between this value and the number of streams."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['tempo'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('tempo scale of 0-200 Beats Per Minute')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph describes the tempo of a song comapred to the number of streams that song has. Given our dataset, it is unclear whether there is a correlation between the tempo of a song and the number of streams it gets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "There appeared to be a potential relationship between valence and the number of streams a song was getting, so it might be interesting to look at what the different features are like for songs with a valence of around .4 or higher"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTopTracks = top5s.loc[top5s['valence'] > .4]\n",
    "highValenceTopTracks.sort_values('streams', ascending=False).head(10)"
   ]
  },
  {
   "source": [
    "We have duplicate pieces of data, so lets remove the duplicates for this test. We're going to try to keep the versions of the song that have the most streams"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTopTracks = highValenceTopTracks.sort_values('streams', ascending=False).drop_duplicates(['artist', 'duration_ms', 'acousticness', 'danceability', 'energy'], keep='first') # Keeping the last seen version of each song, as that will probably hold it's total streams more accurately\n",
    "highValenceTopTracks.sort_values('streams', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTopTracks = highValenceTopTracks.sort_values('valence', ascending=False)\n",
    "highValenceTopTracks.head()"
   ]
  },
  {
   "source": [
    "We believe no one feature has a strong effect on the number of streams, but it's possible that a combination of values in different features work together to improve stream count."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Using our list of songs with a high valence, we can look at the relationship between featuers like danceability or tempo and stream count to try to see how songs with both a high valence and varying levels of these features affect streams."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's get high valence songs from our original dataframe to have a larger sample size"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTracks = df.loc[(df['valence'] > .5) & (df['valence'] < .8)]\n",
    "veryHighValenceTracks = df.loc[df['valence'] > .8]\n",
    "lowValenceTracks = df.loc[(df['valence'] < .5) & (df['valence'] > .3)]\n",
    "veryLowValenceTracks = df.loc[df['valence'] < .3]\n",
    "#lowValenceTracks.head()\n",
    "#highValenceTracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting songs with a high valence and varying levels of danceability against streams to see if these two values work together to impact stream counts\n",
    "plt.scatter(veryLowValenceTracks['danceability'],veryLowValenceTracks['streams'], color=\"blue\")\n",
    "plt.scatter(lowValenceTracks['danceability'],lowValenceTracks['streams'], color=\"turquoise\")\n",
    "plt.scatter(highValenceTracks['danceability'],highValenceTracks['streams'], color=\"yellow\")\n",
    "plt.scatter(veryHighValenceTracks['danceability'],veryHighValenceTracks['streams'], color=\"red\")\n",
    "plt.title('Danceability and streams for songs with bounded valences')\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(['Song with valence > .8', 'Song with valence > .5 and < .8', 'Song with valence < .5 and > .3', 'Song with valence < .3'])"
   ]
  },
  {
   "source": [
    "This graph displays how the danceability of a song compares to the number of streams it has for songs that have a high valence (>.5). While there is little indication of a linear correlation, it appears that the songs with the most streams all also have a danceability of > .5. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "No longer seeing the relationship we were seeing earlier between valence and number of streams. Maybe the relationship that leads to more streams is a combination of these features together. It might be worth trying to see if there is a relationship between streams and a combination of features like valence AND loudness or tempo AND danceability"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Instead of considering high valence songs, let's looks at the top streamed songs for the 1st day of every month in the year of 2017"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top500OverYear = df.sort_values('streams', ascending=False).drop_duplicates(['artist', 'duration_ms', 'acousticness', 'danceability', 'energy'], keep='first').head(500)\n",
    "top500OverYear.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "plt.scatter(top500OverYear['valence'], top500OverYear['tempo'], top500OverYear['streams'])\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "source": [
    "It seems like each individual feature has very little effect on the number of streams, which would support our findings above. After seeing this, we had a couple of ideas. It is possible different features we are currently tracking work together to make a song popular, but it is also possible we are missing other important features. After looking back at the most popular songs over the course of our entire dataframe, we noticed the majority of artists were well known or already accomplished. While it is obvious that an artists \"followers\" or typical listeners will increase the number of streams a song will get, it would be interesting to know if the number of typical listeners was more important than all these other aspects of the song."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We can start by getting the number of followers each artist has for every track entry in our dataframe. The Spotify API also provides a \"popularity\" index from 0 to 100, with 100 being the most popular. We will get this information, as well. There will be repetition between duplicate entries for an artist, but we are keeping these in so that we can still build a dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_index_list = []\n",
    "num_followers_list = []\n",
    "for index, row in df.iterrows():\n",
    "    print(row)\n",
    "    artist_object = sp.artist(row['artist_id'])\n",
    "    followers_object = artist_object['followers']\n",
    "    popularity_value = artist_object['popularity']\n",
    "print(popularity_index_list)\n",
    "print(num_followers_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
