{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Data of Top 200 songs on Spotify\n",
    "## Amanuel Awoke\n",
    "##  Ferzam M\n",
    "## Josue Velasquez"
   ]
  },
  {
   "source": [
    "# Introduction\n",
    "## Motivation\n",
    "The music industry has changed a lot in the last decade with the introduction of streaming services like Apple Music or Spotify. Services like Spotify allow users to livestream music for personal consumption, often for free or for a subscription fee. These services have made it easier to consume music and have increased opportunities for people to start producing music, but they have also changed how musicians make money. Whenever a user listens to a song on a streaming service, the service typically keeps track of the number of “plays” that song has. Music artists are then paid a small amount based on the number of plays they have accumulated for their music. Given how little these artists are paid from streaming services, maximizing the amount of revenue made from a song seems pretty valuable for those looking to push out music to these services. Play count also indicates where a song stands in the streaming services’ popularity lists, and making it onto their top 100 or 200 songs is a factor considered in whether these songs are added to global, official top songs charts i.e. Billboard 200.\n",
    " \n",
    "Our group thought it would be interesting to see if we could try to make predictions for how popular a song might be given different features for a song (e.g. the genre of the song, how fast or slow it is, the key the song is written in, the time of year a song was released, how many listeners an artist already gets on average, etc.). If we can indicate how many plays a song will get, we can give a prediction for how much money a song will make on a streaming service. Much like the Moneyball scenario, it’s possible that artists are focusing on producing music that meets criteria which they think makes a song popular when, in reality, they should be focusing on other aspects of their music. Understanding what components of a song make it popular would help artists figure out the best way to produce music in order to make money off of these streaming services.\n",
    "\n",
    "The Moneyball story demonstrated the importance of data science in producing a strong baseball team, and while music is different from sports, our project should hopefully reflect similar data science practices in order to reach a valuable conclusion. It may be relatively straightforward to look at aspects like which genres make the most money or whether a song by Taylor Swift will end up on the top 200 chart given her “incredibly loyal fanbase” of over 40 million people, but maybe there are other similarities between popular songs that could indicate factors which help make a song more popular. Data science practices like t-tests (maybe) or machine learning models help us here by giving us tools to help identify characteristics in a song, clarify how those characteristics might relate to play count, and predict what the play count (or popularity) for a similar song could be given factors that we have determined have an affect on play count (or popularity)\n",
    "<One valuable conclusion might be the LACK OF money artists are being paid from streaming services, or how little they make off streaming services alone>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Collect Data\n",
    "\n",
    "This is the first step in the data lifecycle where we must identify information to web scrape. We gather data from the [Spotify Charts Regional Top 200](https://spotifycharts.com/regional) to first identify which songs had the highest stream counts in the United States, dating back to January 1st 2017, to current day. Spotify Charts provides tracks with the highest stream count, their top 200 rank, and the artist(s) who created that song. Spotify Charts already compiles the data into Excel tables, so it isn't necessary to directly scrape from the website. If you wanted to download one yourself, at the top right of the website, select a date you'd like to download in the dropdown, then select further up \"Download to CSV.\" The pandas method read_csv() was used to process the Excel files into dataframes.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spotipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were consistent download URLs of Excel sheets in relation to the date they recorded, we used a looped to retreive the links then later download all sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect links from spotify charts top 200 streams per day\n",
    "ref_str = \"https://spotifycharts.com/regional/global/daily/\"\n",
    "ref_arr = []\n",
    "# gets every day from janurary 2017 to October 2020\n",
    "\n",
    "# for year in range(2017, 2021):\n",
    "for year in range(2017, 2018):\n",
    "    date = \"\"\n",
    "    \n",
    "    endingMonth = 12\n",
    "    if year == 2020:\n",
    "        endingMonth = 10\n",
    "        \n",
    "    # for month in range (1, endingMonth + 1):\n",
    "    for month in range (1,2):\n",
    "       \n",
    "        dayCount = -1\n",
    "\n",
    "        #gets proper day count per month\n",
    "        thirtyDayCountMonths = [4, 6, 9, 11]\n",
    "        if month == 2:\n",
    "            dayCount = 29\n",
    "        elif month in thirtyDayCountMonths:\n",
    "            dayCount = 30\n",
    "        else:\n",
    "            dayCount = 31\n",
    "\n",
    "        if int(month) < 10:\n",
    "            month = \"0\" + str(month)\n",
    "        # for day in range (1, daycount + 1):\n",
    "        for day in range (1, 16):\n",
    "           \n",
    "            if int(day) < 10:\n",
    "                day = \"0\" + str(day)\n",
    "\n",
    "            date = str(year) + \"-\" + str(month) + \"-\" + str(day) + \"/download\"\n",
    "            date = ref_str + date\n",
    "            ref_arr.append(date)\n",
    "\n",
    "ref_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop downloading and appending of dataframes \n",
    "\n",
    "df = pd.DataFrame(columns =['position', 'track_name', 'artist', 'streams', 'url', 'date'] )\n",
    "#make dir to save to\n",
    "path = \"sheets\"\n",
    "folderExists = False\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    print (\"Folder already exists\")\n",
    "    folderExists = True\n",
    "\n",
    "    for i in ref_arr:\n",
    "\n",
    "        r = requests.get(i, allow_redirects = True)\n",
    "        #String manipulation to read from the correct csv files\n",
    "        date = i[48:58]\n",
    "        fileName = \"regional-global-daily-\" + date + \".csv\"\n",
    "        if not folderExists:\n",
    "            print(\"Downloading... \" + filename)\n",
    "            open(fileName, \"wb\").write(r.content)\n",
    "\n",
    "            os.rename(fileName, \"sheets/\" + fileName)\n",
    "\n",
    "\n",
    "        df_new = pd.read_csv(path + \"/\" + fileName)\n",
    "        df_new.columns= ['position', 'track_name', 'artist', 'streams', 'url']\n",
    "        df_new['date'] = date\n",
    "        \n",
    "        df_new = df_new.iloc[1:] #deletes junk row from csv conversion\n",
    "        df = df.append(df_new)\n",
    "\n",
    "    print(\"Done\")\n",
    "df.drop(['position'], axis=1, inplace=True) #delete position row since rank alraedy has this information\n",
    "#streams are a string of a num, must wrap as type int always\n",
    "df['streams'] = df['streams'].astype(int)"
   ]
  },
  {
   "source": [
    "## Wrangled data into dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "# Data Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "[Spotipy](https://spotipy.readthedocs.io/en/2.16.1/#) is a lightweight Python library for the [Spotify Web API](https://developer.spotify.com/documentation/web-api/) used to retrieve more detailed data for tracks now that their names have been retrieved from the Spotify Top 200. We must first authenticate our usage of the API."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "\n",
    "SPOTIPY_CLIENT_ID=\"ea1a162fbc6f413990542b76ab82a168\"\n",
    "SPOTIPY_CLIENT_SECRET=\"a09882042ce54f158fdd2b6baaf2b26d\"\n",
    "SPOTIPY_CLIENT_REDIRECT=\"http://www.cs.umd.edu/class/fall2020/cmsc320-0201/\"\n",
    "\n",
    "scope = \"user-library-read\"\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope, client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET, redirect_uri=SPOTIPY_CLIENT_REDIRECT))\n",
    "\n",
    "# results = sp.current_user_saved_tracks()\n",
    "\n",
    "\n",
    "# How to get audio features of a track from our data frame\n",
    "#not needed anymore but good refrence for how to get trackdata\n",
    "#trackName = df.iloc[0].at['track_name']\n",
    "#trackNameWithoutSpaces = '+'.join(trackName.split())\n",
    "#print(trackNameWithoutSpaces)\n",
    "#trackItem = sp.search(trackNameWithoutSpaces, 1, 0)\n",
    "#track_id = trackItem['tracks']['items'][0]['id']\n",
    "#audiofeatures = sp.audio_features(track_id)\n",
    "#print(track_id)\n",
    "#audiofeatures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gets artist genres and artist ids for each artist in dataframe and puts them in arrays\n",
    "# artist_genres = []\n",
    "# artist_ids = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     artist = row['artist']\n",
    "#     #print(index)\n",
    "#     #print(artist)\n",
    "#     trackArtistWithoutSpaces = '+'.join(artist.split())\n",
    "#     result = sp.search(trackArtistWithoutSpaces)\n",
    "#     track = result['tracks']['items'][0]\n",
    "#     artist_id = track[\"artists\"][0][\"id\"]\n",
    "#     #print(artist_id)\n",
    "#     #print(track)\n",
    "#     artist_ids.append(artist_id)\n",
    "#     artist = sp.artist(track[\"artists\"][0][\"external_urls\"][\"spotify\"])\n",
    "#     artist_genres.append(artist[\"genres\"])\n",
    "#     #print(artist[\"genres\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add artist id and genres to dataframe\n",
    "# df['Artist Id'] = artist_ids\n",
    "# df['artist_genres'] = artist_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[\"artist_genres\"])\n",
    "\n",
    "#creates new column in dataframe based on genre filter within filter func\n",
    "# def filt_func(genre_list):\n",
    "#     genre = ['pop','rap','edm','rock','indie']\n",
    "#     result = list(filter(lambda x: x in genre, genre_list))\n",
    "#     return \"other\" if len(result) == 0 else result[0]\n",
    "#     #print(result)\n",
    "# df['genre'] = df['artist_genres'].apply(lambda x: filt_func(x))\n",
    "# df['streams'] = df['streams'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "audioFeaturesDf = pd.DataFrame(columns=[\"duration_ms\", \"key\", \"mode\", \"time_signature\", \"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"valence\", \"tempo\", \"id\", \"uri\", \"track_href\", \"analysis_url\", \"type\"])\n",
    "\n",
    "#Example lookup of a song \n",
    "trackName = df.iloc[0].at['track_name']\n",
    "trackNameWithoutSpaces = '+'.join(trackName.split())\n",
    "trackItem = sp.search(trackNameWithoutSpaces, 1, 0)\n",
    "track_id = trackItem['tracks']['items'][0]['id']\n",
    "audiofeatures = sp.audio_features(track_id)\n",
    "print(track_id)\n",
    "print(audiofeatures[0]['danceability'])\n",
    "# print(row['track_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "#Take each song and lookup its audio features, then create a dataframe for them\n",
    "print(\"Searching...\")\n",
    "for index, row in df.iterrows():\n",
    "    trackName = df.iloc[index - 1].at['track_name']\n",
    "    trackNameWithoutSpaces = '+'.join(trackName.split())\n",
    "    trackItem = sp.search(trackNameWithoutSpaces, 1, 0)\n",
    "    audiofeatures = {'duration_ms' : np.nan, 'key' : np.nan, 'mode' : np.nan, 'time_signature' : np.nan, 'acousticness' : np.nan, 'danceability' : np.nan, 'energy' : np.nan, 'instrumentalness' : np.nan, 'liveness' : np.nan, 'loudness' : np.nan, 'speechiness' : np.nan, 'valence' : np.nan, 'tempo' : np.nan, 'id' : np.nan, 'uri' : np.nan, 'track_href' : np.nan, 'analysis_url' : np.nan, 'type' : np.nan, }\n",
    "    if (len(trackItem['tracks']['items']) != 0):\n",
    "        track_id = trackItem['tracks']['items'][0]['id']\n",
    "        audiofeatures = sp.audio_features(track_id)[0]\n",
    "    audioFeaturesDf = audioFeaturesDf.append(audiofeatures, ignore_index=True)\n",
    "toc = time.perf_counter()\n",
    "print(f\"Searches took {toc - tic:0.4f} mf seconds damn\")\n",
    "\n",
    "\n",
    "\n",
    "audioFeaturesDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append audio features to master dataframe\n",
    "audioFeaturesDf\n",
    "df['duration_ms'] = audioFeaturesDf['duration_ms']\n",
    "df['acousticness'] = audioFeaturesDf['acousticness']\n",
    "df['danceability'] = audioFeaturesDf['danceability']\n",
    "df['energy'] = audioFeaturesDf['energy']\n",
    "df['instrumentalness'] = audioFeaturesDf['instrumentalness']\n",
    "df['liveness'] = audioFeaturesDf['liveness']\n",
    "df['loudness'] = audioFeaturesDf['loudness']\n",
    "df['speechiness'] = audioFeaturesDf['speechiness']\n",
    "df['valence'] = audioFeaturesDf['valence']\n",
    "df['tempo'] = audioFeaturesDf['tempo']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "#plotting all the new metrics in our dataframe vs streams"
   ]
  },
  {
   "source": [
    "# Data Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram takes 100 random tracks, takes the average of all their streams, then does this 100 times\n",
    "#Is a standarrd deviation\n",
    "\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "#data = df['tempo'].sample(n=10).array\n",
    "data = []\n",
    "for i in range(0,100):\n",
    "    data.append(np.mean(df['streams'].sample(n=100)))\n",
    "print(data)\n",
    "plt.hist(data)\n",
    "plt.xlabel(\"Estimate\")\n",
    "plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#Get averages of each col\n",
    "duration_mean = np.mean(df['duration_ms'])\n",
    "acousticness_mean = np.mean(df['acousticness'])\n",
    "danceability_mean = np.mean(df['danceability'])\n",
    "energy_mean = np.mean(df['energy'])\n",
    "instrumentalness_mean = np.mean(df['instrumentalness'])\n",
    "liveness_mean = np.mean(df['liveness'])\n",
    "loudness_mean = np.mean(df['loudness'])\n",
    "speechiness_mean = np.mean(df['speechiness'])\n",
    "valence_mean = np.mean(df['valence'])\n",
    "tempo_mean = np.mean(df['tempo'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(duration_mean)\n",
    "# line = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "\n",
    "# for crime in crimes:\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for region in regions:\n",
    "#         x.append(region[\"Total\"].values)\n",
    "#         y.append(region[crime].values)\n",
    "        \n",
    "        \n",
    "#     x = np.array(x)\n",
    "#     x = x.flatten()\n",
    "#     y = np.array(y)\n",
    "#     y = y.flatten()\n",
    "    \n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     plt.title(crime)\n",
    "        \n",
    "# line = linear_model.LinearRegression()\n",
    "# x = np.array(df['duration_ms']).flatten()\n",
    "# y = np.array(df['streams']).flatten()\n",
    "# print(x)\n",
    "# line.fit(x,y)\n",
    "# predicted = line.predict(x.reshape(-1,1))\n",
    "    \n",
    "# #     r_value = line.score(x.reshape(-1,1),y)\n",
    "        \n",
    "        \n",
    "# #     plt.plot(x,predicted, c='r', label=r_value)\n",
    "# #     plt.legend()\n",
    "    \n",
    "# #     plt.show()\n",
    "# #     plt.close()\n",
    "\n",
    "# plt.scatter(x, y)\n",
    "# print(type(df['streams']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do i get rows with values in a range\n",
    "#where dancability\n",
    "\n",
    "# df_dance = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['duration_ms'], df['streams'])\n",
    "plt.xlabel('duration in milliseconds')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['acousticness'],df['streams'])\n",
    "plt.xlabel('accousticness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['danceability'],df['streams'])\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['energy'],df['streams'])\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['instrumentalness'],df['streams'])\n",
    "plt.xlabel('instrumentalness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['liveness'],df['streams'])\n",
    "plt.xlabel('liveness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['loudness'],df['streams'])\n",
    "plt.xlabel('loudness SCALE???????????????????')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['speechiness'],df['streams'])\n",
    "plt.xlabel('speechiness scale of 0-.5')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['valence'],df['streams'])\n",
    "plt.xlabel('valence scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['tempo'],df['streams'])\n",
    "plt.xlabel('tempo scale of 0-200')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#violin plot of genre vs streams in millions\n",
    "# ax = sns.violinplot(x='genre', y='streams', data=df, palette='muted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['date'],df['streams'])\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "source": [
    "# Insight"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}