{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the Data of Top 200 songs on Spotify\n",
    "## Amanuel Awoke\n",
    "##  Ferzam M\n",
    "## Josue Velasquez"
   ]
  },
  {
   "source": [
    "# Introduction\n",
    "## Motivation\n",
    "The music industry has changed a lot in the last decade with the introduction of streaming services like Apple Music or Spotify. Services like Spotify allow users to livestream music for personal consumption, often for free or for a subscription fee. These services have made it easier to consume music and have increased opportunities for people to start producing music, but they have also changed how musicians make money. Whenever a user listens to a song on a streaming service, the service typically keeps track of the number of “plays” that song has. Music artists are then paid a small amount based on the number of plays they have accumulated for their music. Given how little these artists are paid from streaming services, maximizing the amount of revenue made from a song seems pretty valuable for those looking to push out music to these services. Play count also indicates where a song stands in the streaming services’ popularity lists, and making it onto their top 100 or 200 songs is a factor considered in whether these songs are added to global, official top songs charts i.e. Billboard 200.\n",
    " \n",
    "Our group thought it would be interesting to see if we could try to make predictions for how popular a song might be given different features for a song (e.g. the genre of the song, how fast or slow it is, the key the song is written in, the time of year a song was released, how many listeners an artist already gets on average, etc.). If we can indicate how many plays a song will get, we can give a prediction for how much money a song will make on a streaming service. Much like the Moneyball scenario, it’s possible that artists are focusing on producing music that meets criteria which they think makes a song popular when, in reality, they should be focusing on other aspects of their music. Understanding what components of a song make it popular would help artists figure out the best way to produce music in order to make money off of these streaming services.\n",
    "\n",
    "The Moneyball story demonstrated the importance of data science in producing a strong baseball team, and while music is different from sports, our project should hopefully reflect similar data science practices in order to reach a valuable conclusion. It may be relatively straightforward to look at aspects like which genres make the most money or whether a song by Taylor Swift will end up on the top 200 chart given her “incredibly loyal fanbase” of over 40 million people, but maybe there are other similarities between popular songs that could indicate factors which help make a song more popular. Data science practices like t-tests (maybe) or machine learning models help us here by giving us tools to help identify characteristics in a song, clarify how those characteristics might relate to play count, and predict what the play count (or popularity) for a similar song could be given factors that we have determined have an affect on play count (or popularity)\n",
    "<One valuable conclusion might be the LACK OF money artists are being paid from streaming services, or how little they make off streaming services alone>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Collect Data\n",
    "\n",
    "This is the first step in the data lifecycle where we must identify information to web scrape. We gather data from the [Spotify Charts Regional Top 200](https://spotifycharts.com/regional) to first identify which songs had the highest stream counts in the United States, dating back to January 1st 2017, to current day. Spotify Charts provides tracks with the highest stream count, their top 200 rank, and the artist(s) who created that song. Spotify Charts already compiles the data into Excel tables, so it isn't necessary to directly scrape from the website. If you wanted to download one yourself, at the top right of the website, select a date you'd like to download in the dropdown, then select further up \"Download to CSV.\" The pandas method read_csv() was used to process the Excel files into dataframes.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spotipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were consistent download URLs of Excel sheets in relation to the date they recorded, we used a looped to retreive the links then later download all sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect links from spotify charts top 200 streams per day\n",
    "ref_str = \"https://spotifycharts.com/regional/global/daily/\"\n",
    "ref_arr = []\n",
    "\n",
    "# gets every day from janurary 2017 to October 2020\n",
    "\n",
    "# for year in range(2017, 2021):\n",
    "for year in range(2017, 2018):\n",
    "    date = \"\"\n",
    "    \n",
    "    endingMonth = 12\n",
    "    if year == 2020:\n",
    "        endingMonth = 10\n",
    "        \n",
    "    # for month in range (1, endingMonth + 1):\n",
    "    for month in range (1, 13):\n",
    "       \n",
    "        dayCount = -1\n",
    "\n",
    "        #gets proper day count per month\n",
    "        thirtyDayCountMonths = [4, 6, 9, 11]\n",
    "        if month == 2:\n",
    "            dayCount = 29\n",
    "        elif month in thirtyDayCountMonths:\n",
    "            dayCount = 30\n",
    "        else:\n",
    "            dayCount = 31\n",
    "\n",
    "        if int(month) < 10:\n",
    "            month = \"0\" + str(month)\n",
    "        #for day in range (1, 16):\n",
    "           \n",
    "        #    if int(day) < 10:\n",
    "        #        day = \"0\" + str(day)\n",
    "\n",
    "        date = str(year) + \"-\" + str(month) + \"-\" + \"01\" + \"/download\"\n",
    "        date = ref_str + date\n",
    "        ref_arr.append(date)\n",
    "\n",
    "ref_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop downloading and appending of dataframes \n",
    "\n",
    "df = pd.DataFrame(columns =['position', 'track_name', 'artist', 'streams', 'url', 'date'] )\n",
    "#make dir to save to\n",
    "path = \"sheets\"\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    print (\"Folder already exists\")\n",
    "\n",
    "for i in ref_arr:\n",
    "    r = requests.get(i, allow_redirects = True)\n",
    "    #String manipulation to read from the correct csv files\n",
    "    date = i[48:58]\n",
    "    #print(date)\n",
    "    fileName = \"regional-global-daily-\" + date + \".csv\"\n",
    "    #print(fileName)\n",
    "    open(fileName, \"wb\").write(r.content)\n",
    "\n",
    "    #os.rename(fileName, \"sheets/\" + fileName)  \n",
    "\n",
    "    df_new = pd.read_csv(fileName)\n",
    "    df_new.columns= ['position', 'track_name', 'artist', 'streams', 'url']\n",
    "    df_new['date'] = date\n",
    "    \n",
    "    df_new = df_new.iloc[1:] #deletes junk row from csv conversion\n",
    "    df = df.append(df_new)\n",
    "\n",
    "\n",
    "df = df.reset_index() # Sets index back to being the regular 0-based index. This is really helpful when trying to add more to the dataframe later, because otherwise there are lots of duplicate indices\n",
    "#df.drop(['position'], axis=1, inplace=True) #delete position row since rank alraedy has this information"
   ]
  },
  {
   "source": [
    "## Wrangled data into dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "# Data Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "[Spotipy](https://spotipy.readthedocs.io/en/2.16.1/#) is a lightweight Python library for the [Spotify Web API](https://developer.spotify.com/documentation/web-api/) used to retrieve more detailed data for tracks now that their names have been retrieved from the Spotify Top 200. We must first authenticate our usage of the API."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "\n",
    "SPOTIPY_CLIENT_ID=\"ea1a162fbc6f413990542b76ab82a168\"\n",
    "SPOTIPY_CLIENT_SECRET=\"a09882042ce54f158fdd2b6baaf2b26d\"\n",
    "SPOTIPY_CLIENT_REDIRECT=\"http://www.cs.umd.edu/class/fall2020/cmsc320-0201/\"\n",
    "\n",
    "scope = \"user-library-read\"\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope, client_id=SPOTIPY_CLIENT_ID, client_secret=SPOTIPY_CLIENT_SECRET, redirect_uri=SPOTIPY_CLIENT_REDIRECT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gets artist genres and artist ids for each artist in dataframe and puts them in arrays\n",
    "# artist_genres = []\n",
    "# artist_ids = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     artist = row['artist']\n",
    "#     #print(index)\n",
    "#     #print(artist)\n",
    "#     trackArtistWithoutSpaces = '+'.join(artist.split())\n",
    "#     result = sp.search(trackArtistWithoutSpaces)\n",
    "#     track = result['tracks']['items'][0]\n",
    "#     artist_id = track[\"artists\"][0][\"id\"]\n",
    "#     #print(artist_id)\n",
    "#     #print(track)\n",
    "#     artist_ids.append(artist_id)\n",
    "#     artist = sp.artist(track[\"artists\"][0][\"external_urls\"][\"spotify\"])\n",
    "#     artist_genres.append(artist[\"genres\"])\n",
    "#     #print(artist[\"genres\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df[\"artist_genres\"])\n",
    "\n",
    "#creates new column in dataframe based on genre filter within filter func\n",
    "#def filt_func(genre_list):\n",
    "#    genre = ['pop','rap','edm','rock','indie']\n",
    "#    result = list(filter(lambda x: x in genre, genre_list))\n",
    "#    return \"other\" if len(result) == 0 else result[0]\n",
    "    #print(result)\n",
    "#df['genre'] = df['artist_genres'].apply(lambda x: filt_func(x))\n",
    "#df['streams'] = df['streams'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was to help understand how to get the track_id and artist_id from a search query\n",
    "#trackName = df.iloc[0].at['track_name']\n",
    "#trackNameWithoutSpaces = '+'.join(trackName.split())\n",
    "#searchQuery = sp.search(trackNameWithoutSpaces, 1, 0)\n",
    "#track_object = searchQuery['tracks']['items'][0]\n",
    "#artist_object = track_object['artists'][0]\n",
    "#artist_id = artist_object['id']\n",
    "#track_id = track_object['id']\n",
    "#audiofeatures = sp.audio_features(track_id)\n",
    "#print(track_id)\n",
    "#print(artist_id)\n",
    "#print(audiofeatures[0]['danceability'])\n",
    "#print(trackNameWithoutSpaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "artist_id_list = []\n",
    "track_id_list = []\n",
    "audioFeaturesDf = pd.DataFrame()\n",
    "# This gets the artist id and the track id (which is included in the \"audio_features\" search we make)\n",
    "# Does this by making one search through the api and gets the ids from the information returned\n",
    "for index, row in df.iterrows():\n",
    "    trackName = row['track_name']\n",
    "    track_id = \"\"\n",
    "    artist_id = \"\"\n",
    "    print(trackName)\n",
    "    # We need to check if our track_name received was a nan value. Idk how these got in here, but there are nans\n",
    "    if(type(trackName) == str):\n",
    "        trackNameWithoutSpaces = '+'.join(trackName.split())\n",
    "        searchQuery = sp.search(trackNameWithoutSpaces, 1, 0)\n",
    "        if (len(searchQuery['tracks']['items']) != 0):\n",
    "            track_object = searchQuery['tracks']['items'][0]\n",
    "            artist_object = track_object['artists'][0] if type(track_object['artists']) is list else track_object['artists']\n",
    "            artist_id = artist_object['id']\n",
    "            track_id = track_object['id']\n",
    "            artist_id_list.append(artist_id)\n",
    "            track_id_list.append(track_id)\n",
    "        # If our query returned nothing then append a nan in the place of artist and track for this entry\n",
    "        else:\n",
    "            artist_id_list.append(np.nan)\n",
    "            track_id_list.append(np.nan)\n",
    "        #print(trackItem)\n",
    "    # If we had stored a nan, then just plan to append a nan in this position\n",
    "    else:\n",
    "        artist_id_list.append(np.nan)\n",
    "        track_id_list.append(np.nan)\n",
    "    audiofeatures = {'duration_ms' : np.nan, 'key' : np.nan, 'mode' : np.nan, 'time_signature' : np.nan, 'acousticness' : np.nan, 'danceability' : np.nan, 'energy' : np.nan, 'instrumentalness' : np.nan, 'liveness' : np.nan, 'loudness' : np.nan, 'speechiness' : np.nan, 'valence' : np.nan, 'tempo' : np.nan, 'id' : np.nan, 'uri' : np.nan, 'track_href' : np.nan, 'analysis_url' : np.nan, 'type' : np.nan, }\n",
    "    #print(audiofeatures)\n",
    "    # If we successfully found a track when we did our seach, then get the audio features for that\n",
    "    if (track_id != \"\"):\n",
    "        audiofeatures = sp.audio_features(track_id)[0]\n",
    "    #print(track_id)\n",
    "    #print(audiofeatures)\n",
    "    audioFeaturesDf = audioFeaturesDf.append(audiofeatures, ignore_index=True)\n",
    "    \n",
    "audioFeaturesDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFeaturesDf['artist_id'] = artist_id_list\n",
    "audioFeaturesDf.head(205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFeaturesDf\n",
    "df['duration_ms'] = audioFeaturesDf['duration_ms']\n",
    "df['acousticness'] = audioFeaturesDf['acousticness']\n",
    "df['danceability'] = audioFeaturesDf['danceability']\n",
    "df['energy'] = audioFeaturesDf['energy']\n",
    "df['instrumentalness'] = audioFeaturesDf['instrumentalness']\n",
    "df['liveness'] = audioFeaturesDf['liveness']\n",
    "df['loudness'] = audioFeaturesDf['loudness']\n",
    "df['speechiness'] = audioFeaturesDf['speechiness']\n",
    "df['valence'] = audioFeaturesDf['valence']\n",
    "df['tempo'] = audioFeaturesDf['tempo']\n",
    "df.head(201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "#plotting all the new metrics in our dataframe vs streams\n",
    "df['streams'] = df['streams'].astype(int)\n",
    "df['position'] = df['position'].astype(int)\n",
    "df.loc[df['position'] == 1].head() # Previously this was showing that every "
   ]
  },
  {
   "source": [
    "Here are the features for the first few songs sorted by streams. We will remove duplicates of songs and maintain the versions with the highest streams"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('streams', ascending=False).drop_duplicates(['artist', 'duration_ms', 'acousticness', 'danceability', 'energy'], keep='first').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import normaltest\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "alpha = 0.05\n",
    "#data = df['tempo'].sample(n=10).array\n",
    "data = []\n",
    "for i in range(0,100):\n",
    "    data.append(np.mean(df['streams'].sample(n=100)))\n",
    "print(data)\n",
    "plt.hist(data)\n",
    "plt.xlabel(\"Estimate\")\n",
    "plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#Get averages of each col\n",
    "duration_mean = np.mean(df['duration_ms'])\n",
    "acousticness_mean = np.mean(df['acousticness'])\n",
    "danceability_mean = np.mean(df['danceability'])\n",
    "energy_mean = np.mean(df['energy'])\n",
    "instrumentalness_mean = np.mean(df['instrumentalness'])\n",
    "liveness_mean = np.mean(df['liveness'])\n",
    "loudness_mean = np.mean(df['loudness'])\n",
    "speechiness_mean = np.mean(df['speechiness'])\n",
    "valence_mean = np.mean(df['valence'])\n",
    "tempo_mean = np.mean(df['tempo'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(duration_mean)\n",
    "# line = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "\n",
    "# for crime in crimes:\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for region in regions:\n",
    "#         x.append(region[\"Total\"].values)\n",
    "#         y.append(region[crime].values)\n",
    "        \n",
    "        \n",
    "#     x = np.array(x)\n",
    "#     x = x.flatten()\n",
    "#     y = np.array(y)\n",
    "#     y = y.flatten()\n",
    "    \n",
    "    \n",
    "#     plt.scatter(x, y)\n",
    "#     plt.title(crime)\n",
    "        \n",
    "# line = linear_model.LinearRegression()\n",
    "# x = np.array(df['duration_ms']).flatten()\n",
    "# y = np.array(df['streams']).flatten()\n",
    "# print(x)\n",
    "# line.fit(x,y)\n",
    "# predicted = line.predict(x.reshape(-1,1))\n",
    "    \n",
    "# #     r_value = line.score(x.reshape(-1,1),y)\n",
    "        \n",
    "        \n",
    "# #     plt.plot(x,predicted, c='r', label=r_value)\n",
    "# #     plt.legend()\n",
    "    \n",
    "# #     plt.show()\n",
    "# #     plt.close()\n",
    "\n",
    "# plt.scatter(x, y)\n",
    "# print(type(df['streams']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how do i get rows with values in a range\n",
    "#where dancability\n",
    "\n",
    "# df_dance = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['duration_ms'], df['streams'])\n",
    "plt.xlabel('duration in milliseconds')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['acousticness'],df['streams'])\n",
    "plt.xlabel('accousticness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['danceability'],df['streams'])\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['energy'],df['streams'])\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['instrumentalness'],df['streams'])\n",
    "plt.xlabel('instrumentalness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['liveness'],df['streams'])\n",
    "plt.xlabel('liveness scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['loudness'],df['streams'])\n",
    "plt.xlabel('loudness in decibels')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['speechiness'],df['streams'])\n",
    "plt.xlabel('speechiness scale of 0-.5')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['valence'],df['streams'])\n",
    "plt.xlabel('valence scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['tempo'],df['streams'])\n",
    "plt.xlabel('tempo scale of 0-200')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#violin plot of genre vs streams in millions\n",
    "# ax = sns.violinplot(x='genre', y='streams', data=df, palette='muted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['date'],df['streams'])\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "source": [
    "Can we find any trends within these features for the top 5 songs from all the months we look at in our dataframe?\n",
    "\n",
    "Going to standardize the number of streams to help us more easily visualize data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['streams'] = df['streams'] / df['streams'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5s = df.loc[df['position'] <= 5]\n",
    "top5s.head(10)"
   ]
  },
  {
   "source": [
    "We're going to try to take a look at the same comparisons we made in the graphs above, but only for the top 10 tracks for the 1st of January. These tracks have the most streams compared to all the other songs from that day, so it could be valuable to see if there are any features that made them so successful. Going on only plot features where data appeared to be more spread out in previous plots."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_list = ['r', 'cyan', 'purple', 'b', 'green']\n",
    "\n",
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['duration_ms'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('duration in milliseconds')\n",
    "plt.ylabel('streams in millions')\n",
    "plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])\n"
   ]
  },
  {
   "source": [
    "This graph Shows how the duration of a song in milliseconds compares to the number of streams that song received, and we're only using the first 10 pieces of data from our dataframe. This shows us that the songs with the most streams from this set of data are songs which are > 240000 ms, or 4 minutes. This is surprising, because the average song is usually around 3 minutes and 30 seconds or less."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['acousticness'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('accousticness scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph displays a confidence score for how likely it is that a song is acoustic (with a value of 1 being very likely that the song is acoustic) compared to the number of streams the song has. All of the confidence scores are less than .5, which indicates most of these songs are probably not acoustic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['energy'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph shows how the \"energy\" of a song, or generally how noisy and fast the song is, compares to the number of streams for the top 10 songs on the 1st of January. Here, we see that the songs with the most streams are around or above .6 on the energy scale (a higher score means the song is higher energy)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['danceability'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('danceability scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph shows how \"danceable\" a song is using a value provided to us by the Spotify API comapred to the number of streams that song got. Danceability is measured as a value from 0 to 1, where 1 is most danceable. This graph appears to be similar to the graph describing, so they may have been determined using similar characteristisc (i.e. both are measuring how upbeat or fast a song is)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['loudness'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('loudness in decibels')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph describes the average volume of each track in our top 5s data set compared to the number of streams each song had. It appears to trend similarly to the last two graphs, indicating that the volume of a track may be correlated with how danceable or energetic a song is."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['valence'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('valence scale of 0-1')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph describes the \"valence\" of a song compared to the # of streams it got. Valence is described as the \"positivity\" of a song where \"Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry),\" according to the Spotify API reference. The reference does not describe how this value is determined, but our data seems to show there may be a correlation between valence and the number of streams a song is getting in the set of number 1 songs. However, this graph does not take into account the other features for the songs. It may be worth trying to consider songs where features except for this one are held to a constant, so that we can consider if there is a correlation between this value and the number of streams."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in top5s.iterrows():\n",
    "    plt.scatter(row['tempo'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('tempo scale of 0-200 Beats Per Minute')\n",
    "plt.ylabel('streams in millions')\n",
    "#plt.legend(['Number 1 Song For Month', 'Number 2 Song For Month', 'Number 3 Song For Month', 'Number 4 Song For Month', 'Number 5 Song For Month'])"
   ]
  },
  {
   "source": [
    "This graph describes the tempo of a song comapred to the number of streams that song has. Given our dataset, it is unclear whether there is a correlation between the tempo of a song and the number of streams it gets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "There appeared to be a potential relationship between valence and the number of streams a song was getting, so it might be interesting to look at what the different features are like for songs with a valence of around .4 or higher"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTopTracks = top5s.loc[top5s['valence'] > .4]\n",
    "highValenceTopTracks.sort_values('streams', ascending=False).head(10)"
   ]
  },
  {
   "source": [
    "We have duplicate pieces of data, so lets remove the duplicates for this test. We're going to try to keep the versions of the song that have the most streams"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTopTracks = highValenceTopTracks.sort_values('streams', ascending=False).drop_duplicates(['artist', 'duration_ms', 'acousticness', 'danceability', 'energy'], keep='first') # Keeping the last seen version of each song, as that will probably hold it's total streams more accurately\n",
    "highValenceTopTracks.sort_values('streams', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highValenceTopTracks = highValenceTopTracks.sort_values('valence', ascending=False)\n",
    "highValenceTopTracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for index, row in highValenceTopTracks.iterrows():\n",
    "    plt.scatter(row['valence'],row['streams'], color=color_list[i])\n",
    "    i = (i + 1) % 5\n",
    "\n",
    "plt.xlabel('valence scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  },
  {
   "source": [
    "No longer seeing the relationship we were seeing earlier between valence and number of streams. Maybe the relationship that leads to more streams is a combination of these features together. It might be worth trying to see if there is a relationship between streams and a combination of features like valence AND loudness or tempo AND danceability"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Instead of considering high valence songs, let's looks at the top streamed songs for the 1st day of every month in the year of 2017"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top500OverYear = df.sort_values('streams', ascending=False).drop_duplicates(['artist', 'duration_ms', 'acousticness', 'danceability', 'energy'], keep='first').head(500)\n",
    "top500OverYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "plt.scatter(top500OverYear['valence'], top500OverYear['tempo'], top500OverYear['streams'])\n",
    "plt.xlabel('energy scale of 0-1')\n",
    "plt.ylabel('streams in millions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}